{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd2c0f6a-1ac3-4a8f-8e8e-083f3aa9c721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'intel-extension-for-transformers' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "!git clone https://github.com/intel/intel-extension-for-transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e121f01-b289-48d5-9b0e-5186bb99fdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: intel-extension-for-transformers in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (1.4.2)\n",
      "Requirement already satisfied: packaging in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from intel-extension-for-transformers) (23.2)\n",
      "Requirement already satisfied: numpy in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from intel-extension-for-transformers) (1.23.5)\n",
      "Requirement already satisfied: schema in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from intel-extension-for-transformers) (0.7.7)\n",
      "Requirement already satisfied: pyyaml in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from intel-extension-for-transformers) (6.0.1)\n",
      "Requirement already satisfied: neural-compressor in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from intel-extension-for-transformers) (2.6)\n",
      "Requirement already satisfied: transformers in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from intel-extension-for-transformers) (4.41.2)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from neural-compressor->intel-extension-for-transformers) (1.2.14)\n",
      "Requirement already satisfied: opencv-python-headless in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from neural-compressor->intel-extension-for-transformers) (4.10.0.84)\n",
      "Requirement already satisfied: pandas in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from neural-compressor->intel-extension-for-transformers) (2.2.2)\n",
      "Requirement already satisfied: Pillow in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from neural-compressor->intel-extension-for-transformers) (10.2.0)\n",
      "Requirement already satisfied: prettytable in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from neural-compressor->intel-extension-for-transformers) (3.10.0)\n",
      "Requirement already satisfied: psutil in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from neural-compressor->intel-extension-for-transformers) (5.9.8)\n",
      "Requirement already satisfied: py-cpuinfo in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from neural-compressor->intel-extension-for-transformers) (9.0.0)\n",
      "Requirement already satisfied: requests in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from neural-compressor->intel-extension-for-transformers) (2.32.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from neural-compressor->intel-extension-for-transformers) (1.4.0)\n",
      "Requirement already satisfied: pycocotools in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from neural-compressor->intel-extension-for-transformers) (2.0.8)\n",
      "Requirement already satisfied: filelock in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from transformers->intel-extension-for-transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from transformers->intel-extension-for-transformers) (0.23.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from transformers->intel-extension-for-transformers) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from transformers->intel-extension-for-transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from transformers->intel-extension-for-transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from transformers->intel-extension-for-transformers) (4.66.4)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from deprecated>=1.2.13->neural-compressor->intel-extension-for-transformers) (1.16.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers->intel-extension-for-transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers->intel-extension-for-transformers) (4.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from pandas->neural-compressor->intel-extension-for-transformers) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from pandas->neural-compressor->intel-extension-for-transformers) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from pandas->neural-compressor->intel-extension-for-transformers) (2023.4)\n",
      "Requirement already satisfied: wcwidth in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from prettytable->neural-compressor->intel-extension-for-transformers) (0.2.13)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from pycocotools->neural-compressor->intel-extension-for-transformers) (3.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from requests->neural-compressor->intel-extension-for-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from requests->neural-compressor->intel-extension-for-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from requests->neural-compressor->intel-extension-for-transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from requests->neural-compressor->intel-extension-for-transformers) (2024.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from scikit-learn->neural-compressor->intel-extension-for-transformers) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from scikit-learn->neural-compressor->intel-extension-for-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from scikit-learn->neural-compressor->intel-extension-for-transformers) (3.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers) (3.1.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers) (6.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->neural-compressor->intel-extension-for-transformers) (1.16.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers) (3.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install intel-extension-for-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b4ca714-49c9-4f5e-aad1-eaccfa7866c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/u950971748705b626d974ffe6e6e3b74/Training/AI/GenAI/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: accelerate in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (0.31.0)\n",
      "Requirement already satisfied: cchardet in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (2.1.7)\n",
      "Requirement already satisfied: einops in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (0.8.0)\n",
      "Requirement already satisfied: evaluate in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.4.2)\n",
      "Requirement already satisfied: fastapi in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (0.111.0)\n",
      "Requirement already satisfied: fschat==0.2.35 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (0.2.35)\n",
      "Requirement already satisfied: huggingface_hub in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (0.23.4)\n",
      "Requirement already satisfied: intel_extension_for_pytorch==2.3.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (2.3.0)\n",
      "Requirement already satisfied: lm-eval in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (0.4.2)\n",
      "Requirement already satisfied: neural-compressor in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (2.6)\n",
      "Requirement already satisfied: neural_speed==1.0a0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 11)) (1.0a0)\n",
      "Requirement already satisfied: numpy==1.23.5 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 12)) (1.23.5)\n",
      "Requirement already satisfied: onnx>=1.15.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 13)) (1.16.1)\n",
      "Requirement already satisfied: optimum in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 14)) (1.20.0)\n",
      "Requirement already satisfied: optimum-intel in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 15)) (1.18.0)\n",
      "Requirement already satisfied: peft==0.6.2 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 16)) (0.6.2)\n",
      "Requirement already satisfied: pydantic==1.10.13 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 17)) (1.10.13)\n",
      "Requirement already satisfied: python-dotenv in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 18)) (1.0.1)\n",
      "Requirement already satisfied: python-multipart in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 19)) (0.0.9)\n",
      "Requirement already satisfied: rouge_score in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 20)) (0.1.2)\n",
      "Requirement already satisfied: sacremoses in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 21)) (0.1.1)\n",
      "Requirement already satisfied: shortuuid in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 22)) (1.0.13)\n",
      "Requirement already satisfied: starlette in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 23)) (0.37.2)\n",
      "Requirement already satisfied: tensorflow>=2.13.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 24)) (2.16.2)\n",
      "Requirement already satisfied: torch==2.3.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 25)) (2.3.0)\n",
      "Requirement already satisfied: torchaudio==2.3.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 26)) (2.3.0)\n",
      "Requirement already satisfied: transformers>=4.35.2 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 27)) (4.41.2)\n",
      "Requirement already satisfied: transformers_stream_generator in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 28)) (0.0.5)\n",
      "Requirement already satisfied: uvicorn in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 29)) (0.30.1)\n",
      "Requirement already satisfied: vllm in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 30)) (0.2.5)\n",
      "Requirement already satisfied: yacs in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from -r requirements.txt (line 31)) (0.1.8)\n",
      "Requirement already satisfied: aiohttp in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from fschat==0.2.35->-r requirements.txt (line 6)) (3.9.5)\n",
      "Requirement already satisfied: httpx in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from fschat==0.2.35->-r requirements.txt (line 6)) (0.27.0)\n",
      "Requirement already satisfied: markdown2[all] in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from fschat==0.2.35->-r requirements.txt (line 6)) (2.4.13)\n",
      "Requirement already satisfied: nh3 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from fschat==0.2.35->-r requirements.txt (line 6)) (0.2.17)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.0 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from fschat==0.2.35->-r requirements.txt (line 6)) (3.0.42)\n",
      "Requirement already satisfied: requests in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from fschat==0.2.35->-r requirements.txt (line 6)) (2.32.3)\n",
      "Requirement already satisfied: rich>=10.0.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from fschat==0.2.35->-r requirements.txt (line 6)) (13.7.1)\n",
      "Requirement already satisfied: tiktoken in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from fschat==0.2.35->-r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: psutil in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from intel_extension_for_pytorch==2.3.0->-r requirements.txt (line 8)) (5.9.8)\n",
      "Requirement already satisfied: packaging in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from intel_extension_for_pytorch==2.3.0->-r requirements.txt (line 8)) (23.2)\n",
      "Requirement already satisfied: pyyaml in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from peft==0.6.2->-r requirements.txt (line 16)) (6.0.1)\n",
      "Requirement already satisfied: tqdm in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from peft==0.6.2->-r requirements.txt (line 16)) (4.66.4)\n",
      "Requirement already satisfied: safetensors in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from peft==0.6.2->-r requirements.txt (line 16)) (0.4.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from pydantic==1.10.13->-r requirements.txt (line 17)) (4.9.0)\n",
      "Requirement already satisfied: filelock in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from torch==2.3.0->-r requirements.txt (line 25)) (3.15.4)\n",
      "Requirement already satisfied: sympy in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from torch==2.3.0->-r requirements.txt (line 25)) (1.12.1)\n",
      "Requirement already satisfied: networkx in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from torch==2.3.0->-r requirements.txt (line 25)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from torch==2.3.0->-r requirements.txt (line 25)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from torch==2.3.0->-r requirements.txt (line 25)) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from torch==2.3.0->-r requirements.txt (line 25)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from torch==2.3.0->-r requirements.txt (line 25)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from torch==2.3.0->-r requirements.txt (line 25)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from torch==2.3.0->-r requirements.txt (line 25)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from torch==2.3.0->-r requirements.txt (line 25)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from torch==2.3.0->-r requirements.txt (line 25)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from torch==2.3.0->-r requirements.txt (line 25)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from torch==2.3.0->-r requirements.txt (line 25)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from torch==2.3.0->-r requirements.txt (line 25)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from torch==2.3.0->-r requirements.txt (line 25)) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from torch==2.3.0->-r requirements.txt (line 25)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from torch==2.3.0->-r requirements.txt (line 25)) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->-r requirements.txt (line 25)) (12.5.40)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from evaluate->-r requirements.txt (line 4)) (2.20.0)\n",
      "Requirement already satisfied: dill in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from evaluate->-r requirements.txt (line 4)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from evaluate->-r requirements.txt (line 4)) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from evaluate->-r requirements.txt (line 4)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from evaluate->-r requirements.txt (line 4)) (0.70.16)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from fastapi->-r requirements.txt (line 5)) (0.0.4)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from fastapi->-r requirements.txt (line 5)) (5.10.0)\n",
      "Requirement already satisfied: orjson>=3.2.1 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from fastapi->-r requirements.txt (line 5)) (3.10.5)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from fastapi->-r requirements.txt (line 5)) (2.2.0)\n",
      "Requirement already satisfied: jsonlines in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from lm-eval->-r requirements.txt (line 9)) (4.0.0)\n",
      "Requirement already satisfied: numexpr in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from lm-eval->-r requirements.txt (line 9)) (2.10.1)\n",
      "Requirement already satisfied: pybind11>=2.6.2 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from lm-eval->-r requirements.txt (line 9)) (2.13.1)\n",
      "Requirement already satisfied: pytablewriter in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from lm-eval->-r requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: sacrebleu>=1.5.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from lm-eval->-r requirements.txt (line 9)) (2.4.2)\n",
      "Requirement already satisfied: scikit-learn>=0.24.1 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from lm-eval->-r requirements.txt (line 9)) (1.4.0)\n",
      "Requirement already satisfied: sqlitedict in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from lm-eval->-r requirements.txt (line 9)) (2.1.0)\n",
      "Requirement already satisfied: tqdm-multiprocess in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from lm-eval->-r requirements.txt (line 9)) (0.0.11)\n",
      "Requirement already satisfied: zstandard in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from lm-eval->-r requirements.txt (line 9)) (0.22.0)\n",
      "Requirement already satisfied: word2number in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from lm-eval->-r requirements.txt (line 9)) (1.1)\n",
      "Requirement already satisfied: more-itertools in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from lm-eval->-r requirements.txt (line 9)) (10.3.0)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from neural-compressor->-r requirements.txt (line 10)) (1.2.14)\n",
      "Requirement already satisfied: opencv-python-headless in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from neural-compressor->-r requirements.txt (line 10)) (4.10.0.84)\n",
      "Requirement already satisfied: Pillow in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from neural-compressor->-r requirements.txt (line 10)) (10.2.0)\n",
      "Requirement already satisfied: prettytable in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from neural-compressor->-r requirements.txt (line 10)) (3.10.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from neural-compressor->-r requirements.txt (line 10)) (9.0.0)\n",
      "Requirement already satisfied: schema in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from neural-compressor->-r requirements.txt (line 10)) (0.7.7)\n",
      "Requirement already satisfied: pycocotools in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from neural-compressor->-r requirements.txt (line 10)) (2.0.8)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from onnx>=1.15.0->-r requirements.txt (line 13)) (4.25.3)\n",
      "Requirement already satisfied: coloredlogs in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from optimum->-r requirements.txt (line 14)) (15.0.1)\n",
      "Requirement already satisfied: sentencepiece in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from optimum-intel->-r requirements.txt (line 15)) (0.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from optimum-intel->-r requirements.txt (line 15)) (69.1.0)\n",
      "Requirement already satisfied: scipy in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from optimum-intel->-r requirements.txt (line 15)) (1.10.1)\n",
      "Requirement already satisfied: absl-py in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from rouge_score->-r requirements.txt (line 20)) (2.1.0)\n",
      "Requirement already satisfied: nltk in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from rouge_score->-r requirements.txt (line 20)) (3.8.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from rouge_score->-r requirements.txt (line 20)) (1.16.0)\n",
      "Requirement already satisfied: regex in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from sacremoses->-r requirements.txt (line 21)) (2024.5.15)\n",
      "Requirement already satisfied: click in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from sacremoses->-r requirements.txt (line 21)) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from sacremoses->-r requirements.txt (line 21)) (1.3.2)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from starlette->-r requirements.txt (line 23)) (4.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (2.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (0.37.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from transformers>=4.35.2->-r requirements.txt (line 27)) (0.19.1)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from uvicorn->-r requirements.txt (line 29)) (0.14.0)\n",
      "Requirement already satisfied: ninja in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from vllm->-r requirements.txt (line 30)) (1.11.1.1)\n",
      "Requirement already satisfied: ray>=2.5.1 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from vllm->-r requirements.txt (line 30)) (2.31.0)\n",
      "Requirement already satisfied: pyarrow in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from vllm->-r requirements.txt (line 30)) (16.1.0)\n",
      "Requirement already satisfied: xformers>=0.0.23 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from vllm->-r requirements.txt (line 30)) (0.0.26.post1)\n",
      "Requirement already satisfied: aioprometheus[starlette] in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from vllm->-r requirements.txt (line 30)) (23.12.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette->-r requirements.txt (line 23)) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette->-r requirements.txt (line 23)) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette->-r requirements.txt (line 23)) (1.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow>=2.13.0->-r requirements.txt (line 24)) (0.42.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 4)) (0.6)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from email_validator>=2.0.0->fastapi->-r requirements.txt (line 5)) (2.6.1)\n",
      "Requirement already satisfied: typer>=0.12.3 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from fastapi-cli>=0.0.2->fastapi->-r requirements.txt (line 5)) (0.12.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from aiohttp->fschat==0.2.35->-r requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from aiohttp->fschat==0.2.35->-r requirements.txt (line 6)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from aiohttp->fschat==0.2.35->-r requirements.txt (line 6)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from aiohttp->fschat==0.2.35->-r requirements.txt (line 6)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from aiohttp->fschat==0.2.35->-r requirements.txt (line 6)) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from aiohttp->fschat==0.2.35->-r requirements.txt (line 6)) (4.0.3)\n",
      "Requirement already satisfied: certifi in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from httpx->fschat==0.2.35->-r requirements.txt (line 6)) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from httpx->fschat==0.2.35->-r requirements.txt (line 6)) (1.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from jinja2->torch==2.3.0->-r requirements.txt (line 25)) (2.1.4)\n",
      "Requirement already satisfied: namex in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from keras>=3.0.0->tensorflow>=2.13.0->-r requirements.txt (line 24)) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from keras>=3.0.0->tensorflow>=2.13.0->-r requirements.txt (line 24)) (0.11.0)\n",
      "Requirement already satisfied: wcwidth in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from prompt-toolkit>=3.0.0->fschat==0.2.35->-r requirements.txt (line 6)) (0.2.13)\n",
      "Requirement already satisfied: jsonschema in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from ray>=2.5.1->vllm->-r requirements.txt (line 30)) (4.21.1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from ray>=2.5.1->vllm->-r requirements.txt (line 30)) (1.0.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from requests->fschat==0.2.35->-r requirements.txt (line 6)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from requests->fschat==0.2.35->-r requirements.txt (line 6)) (2.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from rich>=10.0.0->fschat==0.2.35->-r requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from rich>=10.0.0->fschat==0.2.35->-r requirements.txt (line 6)) (2.17.2)\n",
      "Requirement already satisfied: portalocker in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from sacrebleu>=1.5.0->lm-eval->-r requirements.txt (line 9)) (2.10.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from sacrebleu>=1.5.0->lm-eval->-r requirements.txt (line 9)) (0.9.0)\n",
      "Requirement already satisfied: colorama in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from sacrebleu>=1.5.0->lm-eval->-r requirements.txt (line 9)) (0.4.6)\n",
      "Requirement already satisfied: lxml in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from sacrebleu>=1.5.0->lm-eval->-r requirements.txt (line 9)) (5.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from scikit-learn>=0.24.1->lm-eval->-r requirements.txt (line 9)) (3.3.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from tensorboard<2.17,>=2.16->tensorflow>=2.13.0->-r requirements.txt (line 24)) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from tensorboard<2.17,>=2.16->tensorflow>=2.13.0->-r requirements.txt (line 24)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from tensorboard<2.17,>=2.16->tensorflow>=2.13.0->-r requirements.txt (line 24)) (3.0.3)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from uvicorn[standard]>=0.12.0->fastapi->-r requirements.txt (line 5)) (0.6.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from uvicorn[standard]>=0.12.0->fastapi->-r requirements.txt (line 5)) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from uvicorn[standard]>=0.12.0->fastapi->-r requirements.txt (line 5)) (0.22.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from uvicorn[standard]>=0.12.0->fastapi->-r requirements.txt (line 5)) (12.0)\n",
      "Requirement already satisfied: quantile-python>=1.1 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from aioprometheus[starlette]->vllm->-r requirements.txt (line 30)) (1.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from coloredlogs->optimum->-r requirements.txt (line 14)) (10.0)\n",
      "Requirement already satisfied: wavedrom in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from markdown2[all]->fschat==0.2.35->-r requirements.txt (line 6)) (2.0.3.post3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from pandas->evaluate->-r requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from pandas->evaluate->-r requirements.txt (line 4)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from pandas->evaluate->-r requirements.txt (line 4)) (2023.4)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from pycocotools->neural-compressor->-r requirements.txt (line 10)) (3.8.2)\n",
      "Requirement already satisfied: DataProperty<2,>=1.0.1 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from pytablewriter->lm-eval->-r requirements.txt (line 9)) (1.0.1)\n",
      "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from pytablewriter->lm-eval->-r requirements.txt (line 9)) (1.1.3)\n",
      "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from pytablewriter->lm-eval->-r requirements.txt (line 9)) (3.2.0)\n",
      "Requirement already satisfied: tabledata<2,>=1.3.1 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from pytablewriter->lm-eval->-r requirements.txt (line 9)) (1.3.3)\n",
      "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from pytablewriter->lm-eval->-r requirements.txt (line 9)) (0.1.6)\n",
      "Requirement already satisfied: typepy<2,>=1.3.2 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval->-r requirements.txt (line 9)) (1.3.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from sympy->torch==2.3.0->-r requirements.txt (line 25)) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow>=2.13.0->-r requirements.txt (line 24)) (7.0.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->fschat==0.2.35->-r requirements.txt (line 6)) (0.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->-r requirements.txt (line 10)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->-r requirements.txt (line 10)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->-r requirements.txt (line 10)) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->-r requirements.txt (line 10)) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->-r requirements.txt (line 10)) (3.1.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->-r requirements.txt (line 10)) (6.1.1)\n",
      "Requirement already satisfied: chardet<6,>=3.0.4 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval->-r requirements.txt (line 9)) (5.2.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->-r requirements.txt (line 5)) (1.5.4)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from jsonschema->ray>=2.5.1->vllm->-r requirements.txt (line 30)) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from jsonschema->ray>=2.5.1->vllm->-r requirements.txt (line 30)) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from jsonschema->ray>=2.5.1->vllm->-r requirements.txt (line 30)) (0.18.0)\n",
      "Requirement already satisfied: svgwrite in /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages (from wavedrom->markdown2[all]->fschat==0.2.35->-r requirements.txt (line 6)) (1.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/intel/oneapi/intelpython/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow>=2.13.0->-r requirements.txt (line 24)) (3.17.0)\n",
      "/home/u950971748705b626d974ffe6e6e3b74/Training/AI/GenAI\n"
     ]
    }
   ],
   "source": [
    "%cd ./intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/\n",
    "!pip install -r requirements.txt\n",
    "%cd ../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96b46aff-d527-4873-941f-ce49f41d127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|training_args.py:2052] 2024-07-14 15:41:28,444 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1727] 2024-07-14 15:41:28,446 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "[WARNING|_logger.py:72] 2024-07-14 15:41:28,481 >> Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "[INFO|training_args.py:2052] 2024-07-14 15:41:28,484 >> PyTorch: setting up devices\n",
      "2024-07-14 15:41:28,487 - _logger.py - intel_extension_for_transformers.transformers.llm.finetuning.finetuning - WARNING - Process rank: 0, device: cpu\n",
      "distributed training: True, 16-bits training: True\n",
      "2024-07-14 15:41:28,488 - finetuning.py - intel_extension_for_transformers.transformers.llm.finetuning.finetuning - INFO - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=0,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=False,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_steps=None,\n",
      "eval_strategy=no,\n",
      "evaluation_strategy=None,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=info,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./intel/runs/Jul14_15-41-28_idc-training-gpu-compute-13,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=True,\n",
      "num_train_epochs=1,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=./intel,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./intel,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=2,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=True,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "[INFO|configuration_utils.py:733] 2024-07-14 15:41:28,726 >> loading configuration file config.json from cache at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/config.json\n",
      "[INFO|configuration_utils.py:796] 2024-07-14 15:41:29,470 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-07-14 15:41:29,576 >> loading file tokenizer.model from cache at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-07-14 15:41:29,581 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-07-14 15:41:29,582 >> loading file special_tokens_map.json from cache at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-07-14 15:41:29,583 >> loading file tokenizer_config.json from cache at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-07-14 15:41:29,587 >> loading file tokenizer.json from cache at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/tokenizer.json\n",
      "Using custom data configuration default-193947439aa3c972\n",
      "2024-07-14 15:41:30,048 - builder.py - datasets.builder - INFO - Using custom data configuration default-193947439aa3c972\n",
      "Loading Dataset Infos from /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages/datasets/packaged_modules/json\n",
      "2024-07-14 15:41:30,051 - info.py - datasets.info - INFO - Loading Dataset Infos from /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages/datasets/packaged_modules/json\n",
      "Generating dataset json (/home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a)\n",
      "2024-07-14 15:41:30,072 - builder.py - datasets.builder - INFO - Generating dataset json (/home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a)\n",
      "Downloading and preparing dataset json/default to /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a...\n",
      "2024-07-14 15:41:30,074 - builder.py - datasets.builder - INFO - Downloading and preparing dataset json/default to /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a...\n",
      "Downloading took 0.0 min\n",
      "2024-07-14 15:41:30,081 - download_manager.py - datasets.download.download_manager - INFO - Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "2024-07-14 15:41:30,092 - download_manager.py - datasets.download.download_manager - INFO - Checksum Computation took 0.0 min\n",
      "Generating train split\n",
      "2024-07-14 15:41:30,118 - builder.py - datasets.builder - INFO - Generating train split\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd29e3ff4cb54c2d8128fd81fcdc0724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to verify splits sizes.\n",
      "2024-07-14 15:41:30,172 - info_utils.py - datasets.utils.info_utils - INFO - Unable to verify splits sizes.\n",
      "Dataset json downloaded and prepared to /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a. Subsequent calls will reuse this data.\n",
      "2024-07-14 15:41:30,183 - builder.py - datasets.builder - INFO - Dataset json downloaded and prepared to /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a. Subsequent calls will reuse this data.\n",
      "Using custom data configuration default-193947439aa3c972\n",
      "2024-07-14 15:41:30,442 - builder.py - datasets.builder - INFO - Using custom data configuration default-193947439aa3c972\n",
      "Loading Dataset Infos from /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages/datasets/packaged_modules/json\n",
      "2024-07-14 15:41:30,446 - info.py - datasets.info - INFO - Loading Dataset Infos from /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages/datasets/packaged_modules/json\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "2024-07-14 15:41:30,452 - builder.py - datasets.builder - INFO - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\n",
      "2024-07-14 15:41:30,453 - info.py - datasets.info - INFO - Loading Dataset info from /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\n",
      "Found cached dataset json (/home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a)\n",
      "2024-07-14 15:41:30,462 - builder.py - datasets.builder - INFO - Found cached dataset json (/home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a)\n",
      "Loading Dataset info from /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\n",
      "2024-07-14 15:41:30,464 - info.py - datasets.info - INFO - Loading Dataset info from /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\n",
      "Using custom data configuration default-193947439aa3c972\n",
      "2024-07-14 15:41:30,717 - builder.py - datasets.builder - INFO - Using custom data configuration default-193947439aa3c972\n",
      "Loading Dataset Infos from /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages/datasets/packaged_modules/json\n",
      "2024-07-14 15:41:30,719 - info.py - datasets.info - INFO - Loading Dataset Infos from /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages/datasets/packaged_modules/json\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "2024-07-14 15:41:30,724 - builder.py - datasets.builder - INFO - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\n",
      "2024-07-14 15:41:30,725 - info.py - datasets.info - INFO - Loading Dataset info from /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\n",
      "Found cached dataset json (/home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a)\n",
      "2024-07-14 15:41:30,731 - builder.py - datasets.builder - INFO - Found cached dataset json (/home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a)\n",
      "Loading Dataset info from /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\n",
      "2024-07-14 15:41:30,732 - info.py - datasets.info - INFO - Loading Dataset info from /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\n",
      "[INFO|modeling_utils.py:3474] 2024-07-14 15:41:30,747 >> loading weights file model.safetensors from cache at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1519] 2024-07-14 15:41:30,752 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:962] 2024-07-14 15:41:30,754 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0685075f365043dba8df1423e6d51204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:4280] 2024-07-14 15:41:33,916 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4288] 2024-07-14 15:41:33,917 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at meta-llama/Llama-2-7b-chat-hf.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:917] 2024-07-14 15:41:34,024 >> loading configuration file generation_config.json from cache at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/generation_config.json\n",
      "[INFO|configuration_utils.py:962] 2024-07-14 15:41:34,027 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_length\": 4096,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"temperature\": 0.6,\n",
      "  \"top_p\": 0.9\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99cf7a52b3c420593a7018108422212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a/cache-e6032edefccd5915.arrow\n",
      "2024-07-14 15:41:34,250 - arrow_dataset.py - datasets.arrow_dataset - INFO - Caching processed dataset at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a/cache-e6032edefccd5915.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a550e27de7e34f7cb9c2dea8a645a9ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a/cache-9f5ebff52cb0a2ab.arrow\n",
      "2024-07-14 15:41:34,304 - arrow_dataset.py - datasets.arrow_dataset - INFO - Caching processed dataset at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a/cache-9f5ebff52cb0a2ab.arrow\n",
      "2024-07-14 15:41:34,321 - finetuning.py - intel_extension_for_transformers.transformers.llm.finetuning.finetuning - INFO - Using data collator of type DataCollatorForSeq2Seq\n",
      "[INFO|trainer.py:641] 2024-07-14 15:41:34,514 >> Using cpu_amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2078] 2024-07-14 15:41:35,262 >> ***** Running training *****\n",
      "[INFO|trainer.py:2079] 2024-07-14 15:41:35,264 >>   Num examples = 28\n",
      "[INFO|trainer.py:2080] 2024-07-14 15:41:35,265 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:2081] 2024-07-14 15:41:35,266 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:2084] 2024-07-14 15:41:35,266 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:2085] 2024-07-14 15:41:35,267 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:2086] 2024-07-14 15:41:35,268 >>   Total optimization steps = 7\n",
      "[INFO|trainer.py:2087] 2024-07-14 15:41:35,272 >>   Number of trainable parameters = 4,194,304\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 07:54, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2329] 2024-07-14 15:51:04,906 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:3410] 2024-07-14 15:51:04,914 >> Saving model checkpoint to ./intel\n",
      "[INFO|tokenization_utils_base.py:2513] 2024-07-14 15:51:04,979 >> tokenizer config file saved in ./intel/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2522] 2024-07-14 15:51:04,981 >> Special tokens file saved in ./intel/special_tokens_map.json\n",
      "2024-07-14 15:51:05,005 - finetuning.py - intel_extension_for_transformers.transformers.llm.finetuning.finetuning - INFO - *** Evaluate After Training***\n",
      "[INFO|trainer.py:3719] 2024-07-14 15:51:05,015 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3721] 2024-07-14 15:51:05,015 >>   Num examples = 3\n",
      "[INFO|trainer.py:3724] 2024-07-14 15:51:05,016 >>   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =        1.0\n",
      "  eval_loss               =     1.4617\n",
      "  eval_ppl                =     4.3133\n",
      "  eval_runtime            = 0:00:32.25\n",
      "  eval_samples            =          3\n",
      "  eval_samples_per_second =      0.093\n",
      "  eval_steps_per_second   =      0.031\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from intel_extension_for_transformers.neural_chat.config import (\n",
    "    ModelArguments,\n",
    "    DataArguments,\n",
    "    FinetuningArguments,\n",
    "    TextGenerationFinetuningConfig,\n",
    ")\n",
    "from intel_extension_for_transformers.neural_chat.chatbot import finetune_model\n",
    "\n",
    "model_args = ModelArguments(model_name_or_path=\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "data_args = DataArguments(train_file=\"alpaca_data.json\", validation_split_percentage=10)  # Increased validation split percentage\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./intel',\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    num_train_epochs=1,\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    save_strategy=\"no\",\n",
    "    log_level=\"info\",\n",
    "    save_total_limit=2,\n",
    "    bf16=True,\n",
    ")\n",
    "finetune_args = FinetuningArguments()\n",
    "finetune_cfg = TextGenerationFinetuningConfig(\n",
    "            model_args=model_args,\n",
    "            data_args=data_args,\n",
    "            training_args=training_args,\n",
    "            finetune_args=finetune_args,\n",
    "        )\n",
    "finetune_model(finetune_cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a710d7e-83aa-4e95-9f27-c46794a47f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|training_args.py:2052] 2024-07-14 16:18:37,715 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1727] 2024-07-14 16:18:37,717 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "[WARNING|_logger.py:72] 2024-07-14 16:18:37,735 >> Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "[INFO|training_args.py:2052] 2024-07-14 16:18:37,738 >> PyTorch: setting up devices\n",
      "2024-07-14 16:18:37,740 - _logger.py - intel_extension_for_transformers.transformers.llm.finetuning.finetuning - WARNING - Process rank: 0, device: cpu\n",
      "distributed training: True, 16-bits training: True\n",
      "2024-07-14 16:18:37,741 - finetuning.py - intel_extension_for_transformers.transformers.llm.finetuning.finetuning - INFO - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=0,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=False,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_steps=None,\n",
      "eval_strategy=no,\n",
      "evaluation_strategy=None,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=info,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./intel-neural/runs/Jul14_16-18-37_idc-training-gpu-compute-13,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=True,\n",
      "num_train_epochs=1,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=./intel-neural,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./intel-neural,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=2,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=True,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "[INFO|configuration_utils.py:733] 2024-07-14 16:18:37,915 >> loading configuration file config.json from cache at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/hub/models--Intel--neural-chat-7b-v3-1/snapshots/c0d379a49c1c0579529d5e6f2e936ddb759552a8/config.json\n",
      "[INFO|configuration_utils.py:796] 2024-07-14 16:18:37,918 >> Model config MistralConfig {\n",
      "  \"_name_or_path\": \"Intel/neural-chat-7b-v3-1\",\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 4096,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-07-14 16:18:38,047 >> loading file tokenizer.model from cache at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/hub/models--Intel--neural-chat-7b-v3-1/snapshots/c0d379a49c1c0579529d5e6f2e936ddb759552a8/tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-07-14 16:18:38,051 >> loading file tokenizer.json from cache at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/hub/models--Intel--neural-chat-7b-v3-1/snapshots/c0d379a49c1c0579529d5e6f2e936ddb759552a8/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-07-14 16:18:38,052 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-07-14 16:18:38,054 >> loading file special_tokens_map.json from cache at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/hub/models--Intel--neural-chat-7b-v3-1/snapshots/c0d379a49c1c0579529d5e6f2e936ddb759552a8/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-07-14 16:18:38,056 >> loading file tokenizer_config.json from cache at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/hub/models--Intel--neural-chat-7b-v3-1/snapshots/c0d379a49c1c0579529d5e6f2e936ddb759552a8/tokenizer_config.json\n",
      "Using custom data configuration default-193947439aa3c972\n",
      "2024-07-14 16:18:38,457 - builder.py - datasets.builder - INFO - Using custom data configuration default-193947439aa3c972\n",
      "Loading Dataset Infos from /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages/datasets/packaged_modules/json\n",
      "2024-07-14 16:18:38,460 - info.py - datasets.info - INFO - Loading Dataset Infos from /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages/datasets/packaged_modules/json\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "2024-07-14 16:18:38,469 - builder.py - datasets.builder - INFO - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\n",
      "2024-07-14 16:18:38,472 - info.py - datasets.info - INFO - Loading Dataset info from /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\n",
      "Found cached dataset json (/home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a)\n",
      "2024-07-14 16:18:38,483 - builder.py - datasets.builder - INFO - Found cached dataset json (/home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a)\n",
      "Loading Dataset info from /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\n",
      "2024-07-14 16:18:38,485 - info.py - datasets.info - INFO - Loading Dataset info from /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\n",
      "Using custom data configuration default-193947439aa3c972\n",
      "2024-07-14 16:18:38,752 - builder.py - datasets.builder - INFO - Using custom data configuration default-193947439aa3c972\n",
      "Loading Dataset Infos from /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages/datasets/packaged_modules/json\n",
      "2024-07-14 16:18:38,755 - info.py - datasets.info - INFO - Loading Dataset Infos from /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages/datasets/packaged_modules/json\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "2024-07-14 16:18:38,768 - builder.py - datasets.builder - INFO - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\n",
      "2024-07-14 16:18:38,772 - info.py - datasets.info - INFO - Loading Dataset info from /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\n",
      "Found cached dataset json (/home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a)\n",
      "2024-07-14 16:18:38,781 - builder.py - datasets.builder - INFO - Found cached dataset json (/home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a)\n",
      "Loading Dataset info from /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\n",
      "2024-07-14 16:18:38,784 - info.py - datasets.info - INFO - Loading Dataset info from /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\n",
      "Using custom data configuration default-193947439aa3c972\n",
      "2024-07-14 16:18:39,086 - builder.py - datasets.builder - INFO - Using custom data configuration default-193947439aa3c972\n",
      "Loading Dataset Infos from /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages/datasets/packaged_modules/json\n",
      "2024-07-14 16:18:39,088 - info.py - datasets.info - INFO - Loading Dataset Infos from /home/u950971748705b626d974ffe6e6e3b74/.local/lib/python3.9/site-packages/datasets/packaged_modules/json\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "2024-07-14 16:18:39,094 - builder.py - datasets.builder - INFO - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\n",
      "2024-07-14 16:18:39,099 - info.py - datasets.info - INFO - Loading Dataset info from /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\n",
      "Found cached dataset json (/home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a)\n",
      "2024-07-14 16:18:39,110 - builder.py - datasets.builder - INFO - Found cached dataset json (/home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a)\n",
      "Loading Dataset info from /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\n",
      "2024-07-14 16:18:39,113 - info.py - datasets.info - INFO - Loading Dataset info from /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\n",
      "[INFO|modeling_utils.py:3474] 2024-07-14 16:18:39,133 >> loading weights file model.safetensors from cache at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/hub/models--Intel--neural-chat-7b-v3-1/snapshots/c0d379a49c1c0579529d5e6f2e936ddb759552a8/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1519] 2024-07-14 16:18:39,140 >> Instantiating MistralForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:962] 2024-07-14 16:18:39,143 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e62912fc6164a94b2d2f39845716690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:4280] 2024-07-14 16:18:51,652 >> All model checkpoint weights were used when initializing MistralForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4288] 2024-07-14 16:18:51,654 >> All the weights of MistralForCausalLM were initialized from the model checkpoint at Intel/neural-chat-7b-v3-1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:917] 2024-07-14 16:18:51,769 >> loading configuration file generation_config.json from cache at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/hub/models--Intel--neural-chat-7b-v3-1/snapshots/c0d379a49c1c0579529d5e6f2e936ddb759552a8/generation_config.json\n",
      "[INFO|configuration_utils.py:962] 2024-07-14 16:18:51,770 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23bb6552ad574705b3d92a664418e870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a/cache-06322059239a72c9.arrow\n",
      "2024-07-14 16:18:51,932 - arrow_dataset.py - datasets.arrow_dataset - INFO - Caching processed dataset at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a/cache-06322059239a72c9.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94c9fa173fd4c498ccb1cb591583c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a/cache-4e16801be877ca51.arrow\n",
      "2024-07-14 16:18:52,044 - arrow_dataset.py - datasets.arrow_dataset - INFO - Caching processed dataset at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/datasets/json/default-193947439aa3c972/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a/cache-4e16801be877ca51.arrow\n",
      "2024-07-14 16:18:52,058 - finetuning.py - intel_extension_for_transformers.transformers.llm.finetuning.finetuning - INFO - Using data collator of type DataCollatorForSeq2Seq\n",
      "[INFO|trainer.py:641] 2024-07-14 16:18:52,281 >> Using cpu_amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,407,872 || all params: 7,245,139,968 || trainable%: 0.04703666202518836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2078] 2024-07-14 16:18:53,073 >> ***** Running training *****\n",
      "[INFO|trainer.py:2079] 2024-07-14 16:18:53,075 >>   Num examples = 28\n",
      "[INFO|trainer.py:2080] 2024-07-14 16:18:53,076 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:2081] 2024-07-14 16:18:53,076 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:2084] 2024-07-14 16:18:53,077 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:2085] 2024-07-14 16:18:53,078 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:2086] 2024-07-14 16:18:53,078 >>   Total optimization steps = 7\n",
      "[INFO|trainer.py:2087] 2024-07-14 16:18:53,083 >>   Number of trainable parameters = 3,407,872\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 11:35, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2329] 2024-07-14 16:32:09,229 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:3410] 2024-07-14 16:32:09,237 >> Saving model checkpoint to ./intel-neural\n",
      "[INFO|tokenization_utils_base.py:2513] 2024-07-14 16:32:09,337 >> tokenizer config file saved in ./intel-neural/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2522] 2024-07-14 16:32:09,343 >> Special tokens file saved in ./intel-neural/special_tokens_map.json\n",
      "2024-07-14 16:32:09,482 - finetuning.py - intel_extension_for_transformers.transformers.llm.finetuning.finetuning - INFO - *** Evaluate After Training***\n",
      "[INFO|trainer.py:3719] 2024-07-14 16:32:09,495 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3721] 2024-07-14 16:32:09,496 >>   Num examples = 3\n",
      "[INFO|trainer.py:3724] 2024-07-14 16:32:09,497 >>   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =        1.0\n",
      "  eval_loss               =      1.022\n",
      "  eval_ppl                =     2.7786\n",
      "  eval_runtime            = 0:00:40.60\n",
      "  eval_samples            =          3\n",
      "  eval_samples_per_second =      0.074\n",
      "  eval_steps_per_second   =      0.025\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from intel_extension_for_transformers.neural_chat.config import (\n",
    "    ModelArguments,\n",
    "    DataArguments,\n",
    "    FinetuningArguments,\n",
    "    TextGenerationFinetuningConfig,\n",
    ")\n",
    "from intel_extension_for_transformers.neural_chat.chatbot import finetune_model\n",
    "\n",
    "model_args = ModelArguments(model_name_or_path=\"Intel/neural-chat-7b-v3-1\")\n",
    "data_args = DataArguments(train_file=\"alpaca_data.json\", validation_split_percentage=10)  # Increased validation split percentage\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./intel-neural',\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    num_train_epochs=1,\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    save_strategy=\"no\",\n",
    "    log_level=\"info\",\n",
    "    save_total_limit=2,\n",
    "    bf16=True,\n",
    ")\n",
    "finetune_args = FinetuningArguments()\n",
    "finetune_cfg = TextGenerationFinetuningConfig(\n",
    "            model_args=model_args,\n",
    "            data_args=data_args,\n",
    "            training_args=training_args,\n",
    "            finetune_args=finetune_args,\n",
    "        )\n",
    "finetune_model(finetune_cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0d489a3-cfce-4f7b-86c8-839c69a63f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:733] 2024-07-14 13:16:04,975 >> loading configuration file config.json from cache at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/config.json\n",
      "[INFO|configuration_utils.py:796] 2024-07-14 13:16:04,980 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model meta-llama/Llama-2-7b-chat-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:2108] 2024-07-14 13:16:05,087 >> loading file tokenizer.model from cache at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-07-14 13:16:05,089 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-07-14 13:16:05,090 >> loading file special_tokens_map.json from cache at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-07-14 13:16:05,091 >> loading file tokenizer_config.json from cache at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-07-14 13:16:05,092 >> loading file tokenizer.json from cache at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/tokenizer.json\n",
      "[INFO|configuration_utils.py:733] 2024-07-14 13:16:05,538 >> loading configuration file config.json from cache at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/config.json\n",
      "[INFO|configuration_utils.py:796] 2024-07-14 13:16:05,543 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3474] 2024-07-14 13:16:05,568 >> loading weights file model.safetensors from cache at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1519] 2024-07-14 13:16:05,579 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:962] 2024-07-14 13:16:05,587 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f11c7cc1615415ca089eaed8b9a8fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:4280] 2024-07-14 13:16:15,669 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4288] 2024-07-14 13:16:15,670 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at meta-llama/Llama-2-7b-chat-hf.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:917] 2024-07-14 13:16:15,768 >> loading configuration file generation_config.json from cache at /home/u950971748705b626d974ffe6e6e3b74/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/generation_config.json\n",
      "[INFO|configuration_utils.py:962] 2024-07-14 13:16:15,769 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_length\": 4096,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"temperature\": 0.6,\n",
      "  \"top_p\": 0.9\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel Corporation is an American multinational technology company that designs, manufactures, and sells computer hardware components and consumer electronics. The company was founded in 1968 by Gordon Moore and Robert Noyce and is headquartered in Santa Clara, California.\n",
      "\n",
      "Intel is one of the largest and most influential technology companies in the world, known for its microprocessors, chipsets, motherboard chips, and other computer hardware components. The company's products are used in a wide range of devices, including desktop and laptop computers, smartphones, tablets, servers, and data centers.\n",
      "\n",
      "Intel's product portfolio includes:\n",
      "\n",
      "1. Microprocessors (CPUs): Intel produces a wide range of microprocessors, including Core i3, Core i5, Core i7, Pentium, Celeron, and Atom processors. These processors are used in laptops, desktops, and servers.\n",
      "2. Chipsets: Intel chipsets are used to connect CPUs to memory, storage, and other peripherals. They provide a range of features such as USB ports, SATA ports, and PCIe lan\n"
     ]
    }
   ],
   "source": [
    "from intel_extension_for_transformers.neural_chat import build_chatbot\n",
    "from intel_extension_for_transformers.neural_chat import PipelineConfig\n",
    "from intel_extension_for_transformers.neural_chat.config import LoadingModelConfig\n",
    "\n",
    "config = PipelineConfig(model_name_or_path='meta-llama/Llama-2-7b-chat-hf',\n",
    "                      loading_config=LoadingModelConfig(peft_path=\"./intel\"))\n",
    "chatbot = build_chatbot(config)\n",
    "response = chatbot.predict(query=\"What is Intel?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0360ac69-3959-43e8-b4a1-afc9d40f47a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from intel_extension_for_transformers.neural_chat import build_chatbot\n",
    "from intel_extension_for_transformers.neural_chat import PipelineConfig\n",
    "from intel_extension_for_transformers.neural_chat.config import LoadingModelConfig\n",
    "\n",
    "config = PipelineConfig(model_name_or_path='Intel/neural-chat-7b-v3-1',\n",
    "                      loading_config=LoadingModelConfig(peft_path=\"./intel-neural\"))\n",
    "chatbot = build_chatbot(config)\n",
    "response = chatbot.predict(query=\"What is Intel?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-chat",
   "language": "python",
   "name": "neural-chat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
